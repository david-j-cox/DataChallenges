{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Cell Detection\n",
    "\n",
    "You work for the data team at a local research hospital. You've been tasked with developing a means to help doctors diagnose breast cancer. You've been given data about biopsied breast cells; where it is benign (not harmful) or malignant (cancerous).\n",
    "\n",
    "### Data\n",
    "\n",
    "The dataset consists of 699 cells for which you have the following features:\n",
    "\n",
    "Sample code number: id number\n",
    "Clump Thickness: 1 - 10\n",
    "Uniformity of Cell Size: 1 - 10\n",
    "Uniformity of Cell Shape: 1 - 10\n",
    "Marginal Adhesion: 1 - 10\n",
    "Single Epithelial Cell Size: 1 - 10\n",
    "Bare Nuclei: 1 - 10\n",
    "Bland Chromatin: 1 - 10\n",
    "Normal Nucleoli: 1 - 10\n",
    "Mitoses: 1 - 10\n",
    "Class: (2 for benign, 4 for malignant)\n",
    "\n",
    "The dataset is also available here: https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['sample', 'clump_thickness', 'unif_cell_size', 'unif_cell_shape', 'marginal_adhesion', \\\n",
    "           'single_epi_size', 'bare_nuclei', 'chromatin', 'nucleoli', 'mitoses', 'cancer_class']\n",
    "raw_data = pd.read_csv('breast-cancer-wisconsin.csv', header=None, names=headers)\n",
    "data = raw_data.copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the different types of values we have for each column\n",
    "for i in headers:\n",
    "    print(i, \"\\n\", data[i].value_counts(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything looks good except for the bare_nuclei column. Remove those with '?' vals. \n",
    "print(len(data))\n",
    "data = data[data.bare_nuclei != \"?\"]\n",
    "data['bare_nuclei'] = data['bare_nuclei'].astype(int)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the different types of values we have for each column\n",
    "print(data['bare_nuclei'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the relationship between these variables. \n",
    "data[headers].hist(bins=10, figsize=(20,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into features and outcome variables\n",
    "outcome = data.cancer_class\n",
    "# Recode benign as 0 and malignant as 1\n",
    "outcome.replace({2:0, 4:1}, inplace=True)\n",
    "features = data.drop(['cancer_class', 'sample'], axis=1)\n",
    "print(list(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick feature engineering. \n",
    "features['ovr_unif'] = data['unif_cell_size'] * data['unif_cell_shape']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some packages\n",
    "import matplotlib\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Some functions\n",
    "def bin_metrics(x, y):\n",
    "    '''Prints four common metrics for evaluating classification predictions.'''\n",
    "    print('Accuracy:', round(metrics.accuracy_score(x, y), 4))\n",
    "    print('Precision:', round(metrics.precision_score(x, y), 4))\n",
    "    print('Recall:', round(metrics.recall_score(x, y), 4))\n",
    "    print('ROC_AUC:,', round(metrics.roc_auc_score(x, y), 4))\n",
    "    print('F1:', round(metrics.f1_score(x, y), 4))\n",
    "\n",
    "def plot_cm(x, y):\n",
    "    cm = confusion_matrix(x, y)\n",
    "    df_cm = pd.DataFrame(cm, columns=np.unique(x), index = np.unique(x))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 20}, fmt='g')# font size\n",
    "    plt.ylim([0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Classifier\n",
    "- Advantages: less prone to over-fitting (except with high-dimensional data); gives size and direction of predictors; easy to implement, interpret, and train.\n",
    "- Disadvantages: assumption of linearity between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,  outcome, test_size=0.20, random_state=649)\n",
    "lr = LogisticRegression(solver='lbfgs')\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "bin_metrics(y_test, y_pred)\n",
    "plot_cm(y_test, y_pred)\n",
    "print(list(features), lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What features of a cell are the largest drivers of malignancy?\n",
    "1. Clump thickness\n",
    "1. Bare nuclei\n",
    "1. Uniform cell shape\n",
    "1. Uniform cell size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What features drive your false positive rate? \n",
    "- Marginal adhesion and chromatin appear to be the main drivers of false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = X_test[(y_test == 0) & (y_pred == 1)] # Isolate the false positive cases\n",
    "TP = X_test[(y_test == 1) & (y_pred ==1)] # Isolare the true positive cases\n",
    "FN = X_test[(y_test == 1) & (y_pred == 0)] # Isolate the false negative cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distribution of features across false positives and true positives\n",
    "print(\"TRUE POSITIVE DISTRIBUTIONS\")\n",
    "TP_hds = list(TP)\n",
    "TP[TP_hds].hist(bins=10, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTRUE NEGATIVE DISTRIBUTIONS\")\n",
    "FP_hds = list(FP)\n",
    "FP[FP_hds].hist(bins=10, figsize=(15, 10))\n",
    "# Looks like chromatin, nucleoli, and cell size might all be different across TP and FP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to look at the distribution comparison\n",
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9)) = plt.subplots(3, 3, figsize=(15, 15))\n",
    "ax1.hist(TP['bare_nuclei'], label='TP')\n",
    "ax1.hist(FP['bare_nuclei'], label='FP', alpha=0.5)\n",
    "ax1.set_xlabel('Bare Nuclei')\n",
    "ax2.hist(TP['chromatin'])\n",
    "ax2.hist(FP['chromatin'], alpha=0.5)\n",
    "ax2.set_xlabel('Chromatin')\n",
    "ax3.hist(TP['clump_thickness'])\n",
    "ax3.hist(FP['clump_thickness'], alpha=0.5)\n",
    "ax3.set_xlabel('Clump Thickness')\n",
    "ax4.hist(TP['marginal_adhesion'])\n",
    "ax4.hist(FP['marginal_adhesion'], alpha=0.5)\n",
    "ax4.set_xlabel('Marginal Adhesion')\n",
    "ax5.hist(TP['mitoses'])\n",
    "ax5.hist(FP['mitoses'], alpha=0.5)\n",
    "ax5.set_xlabel('Mitoses')\n",
    "ax6.hist(TP['nucleoli'])\n",
    "ax6.hist(FP['nucleoli'], alpha=0.5)\n",
    "ax6.set_xlabel('Nucleoli')\n",
    "ax7.hist(TP['single_epi_size'])\n",
    "ax7.hist(FP['single_epi_size'], alpha=0.5)\n",
    "ax7.set_xlabel('Single Epithelial Size')\n",
    "ax8.hist(TP['unif_cell_shape'])\n",
    "ax8.hist(FP['unif_cell_shape'], alpha=0.5)\n",
    "ax8.set_xlabel('Uniform Cell Shape')\n",
    "ax9.hist(TP['unif_cell_size'])\n",
    "ax9.hist(FP['unif_cell_size'], alpha=0.5)\n",
    "ax9.set_xlabel('Uniform Cell Size')\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What features drive your false negative rate?\n",
    "- With only one false positive, it's hard to say. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would a physician use your product?\n",
    "- The physician would enter the list of features for the biopsied cells and it would return a probability that the cell was malignant or benign (framing effects matter so could be a feature of deployment). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would you go about determining the most cost-effective method of detecting malignancy?\n",
    "- Probably look at the relative trade-off between how much information each feature adds compared to the importance of that feature. \n",
    "- For example, single epithelial cell size seems to not be predictive at all. Whereas, clump thickness seems to really important data to collect. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
